#本文引用参考了csdn Ardor-Zhang先生的文章，仅供自我学习使用#

1. 概述
   梯度下降（gradient descent）在机器学习中应用十分的广泛，不论是在线性回归还是Logistic回归中，它的主要目的是通过迭代找到目标函数的最小值，或者收敛到最小值。
2. 梯度下降算法
   一个人被困在山上，需要从山上下来(找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低；因此，下山的路径就无法确定，必须利用自己周围的信息一步一步地找到下山的路。
   这个时候，便可利用梯度下降算法来帮助自己下山。怎么做呢，首先以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着下降方向走一步，然后又继续以当前位置为基准，再找最
   陡峭的地方，再走直到最后到达最低处；同理上山也是如此，只是这时候就变成梯度上升算法了
   2.2 梯度下降
   首先，我们有一个可微分的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，
   然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度 ，然后朝着梯度相反的方向，就能让函数值下降的最快！因为梯度的方向就是函数之变化最快的方向(在后面会详细解释)
   所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是场景中测量方向的手段。那么为什么梯度的方
   向就是最陡峭的方向呢？接下来，我们从微分开始讲起：
       2.2.1 微分
       看待微分的意义，可以有不同的角度，最常用的两种是：
       函数图像中，某点的切线的斜率
       函数的变化率
       2.2.2 梯度
       梯度实际上就是多变量微分的一般化。
       下面这个例子：
       我们可以看到，梯度就是分别对每个变量进行微分，然后用逗号分割开，梯度是用<>包括起来，说明梯度其实一个向量。
       梯度的意义：
           在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率
           在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向
           梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向，这正是我们所需要的。
           只要沿着梯度的方向一直走，就能走到局部的最低点
   2.3 数学解释
   首先给出数学公式：
   
